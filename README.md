## **ğŸ“˜ Table of Contents**
ğŸ“Œ Project Overview

ğŸ—ï¸ Architecture

ğŸ“¦ Features
ğŸ§° Tech Stack
ğŸ—‚ï¸ Data Modeling
âš¡ Streaming Pipeline
â„ï¸ Iceberg Metadata & Versioning
ğŸ“Š Analytics Layer
ğŸš€ Airflow Orchestration
ğŸ“ Repository Structure
â–¶ï¸ How to Run
ğŸ› ï¸ Future Enhancements
ğŸ¤ Contributing
ğŸ“œ License


## ğŸ“Œ Project Overview
This project implements a real-time and historical analytics pipeline using a modern Kappa Architecture. It processes Olist marketplace data using:

Kafka for event streaming

Spark Structured Streaming for data processing

Apache Iceberg on AWS S3 as the lakehouse storage layer

Airflow for orchestration

Snowflake as the analytics warehouse

Kibana for real-time visualization

Power BI for BI reporting

The pipeline delivers both live operational dashboards and deep historical analytics, making it ideal for marketplace, eâ€‘commerce, and dataâ€‘intensive platforms.

## ğŸ—ï¸ Architecture

Below is the high-level architecture describing ingestion, real-time serving, Iceberg storage, and BI analytics.
<img width="1484" height="648" alt="archticture" src="https://github.com/user-attachments/assets/747cab34-015c-4657-bcfb-61d8aaaf9f44" />

ğŸ—‚ï¸ Data Modeling

Dimensions:
dim_customer
dim_seller
dim_product
dim_date

Facts:
fact_order_line
fact_payment

Modeling Notes:

Order-level grain using item detail
No SCD needed for order status (already time-stamped)
No SCD for city/state (low-cardinality, no business impact)
Snowflake Streams + Tasks handle incremental loading, capturing new Iceberg changes and applying them through scheduled MERGE operations

Below is a photo of our DWH schema
<img width="3662" height="1676" alt="drawSQL-image-export-2025-12-05" src="https://github.com/user-attachments/assets/edad3a18-6c5d-4ccd-a43b-0d94355bb287" />






